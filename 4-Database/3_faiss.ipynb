{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d2bc094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"syllabus.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "852c2528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## lazy load\n",
    "pages = []\n",
    "for doc in loader.lazy_load():\n",
    "    pages.append(doc)\n",
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01b9cc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, chunk_overlap=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97a4e619",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_pages=splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bb950d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d14768a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\vijay\\work\\code\\AI\\AgenticAILearning\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f639ea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "977859ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=faiss.IndexFlatL2(384)\n",
    "\n",
    "vector_store=FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b175f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15db9648-967e-4159-89ab-f764af1598ea',\n",
       " 'aa81f96f-26ad-4f94-aeb8-7e0b100a7d2c',\n",
       " '58a02ff3-1d91-434e-b86a-c88c3cc0c4d9',\n",
       " '93d30a8f-c89a-4f4d-8458-5f1c5de331e2',\n",
       " '21a65fae-cfdb-4f39-9780-8f55770a0da7',\n",
       " '8baacd66-59e3-4e5b-8a18-6ecbddc54a18',\n",
       " '89e4a575-49d3-435f-8287-4ebe7805d513',\n",
       " '9493c4dd-5854-46c3-bf38-b6ed130ff1f5',\n",
       " 'b7670a57-b447-4090-bc53-3ed242798f0b',\n",
       " '1ed53dec-cbae-46ff-85ff-4129193607f5',\n",
       " '30db158e-f9d4-4b02-97f9-f2810f68a404',\n",
       " '790290c4-6219-4cd1-be7e-e5d28919cfcd',\n",
       " 'd3f2a326-10cb-461c-92ac-d692f3dfd3d7',\n",
       " 'cca0e4d6-7430-41af-af8f-4140ce9e25ca',\n",
       " 'dc39d08c-1e68-4ee0-9572-d93f4c19f7d1',\n",
       " '1f71ba54-cdd1-4ae7-95d6-e6892d930042',\n",
       " 'eb6844dc-fd7b-4a36-b150-4fa9116fc3f9',\n",
       " '5e933cb7-fc36-40cc-9e75-d4b78a886816',\n",
       " 'e5e891bd-b872-4d2e-9c0f-c3e4f0fe23d4',\n",
       " '328c3182-6fd4-4737-9753-60142d4f16b6',\n",
       " '781e0b05-9b8a-4cd1-a0f1-62a8f2651ef9',\n",
       " 'c2e255a7-a47c-40d5-be60-582905d9127c',\n",
       " '5a66be3d-0790-4ee0-a002-a86f431245dd',\n",
       " 'a3bc09cf-7811-4d06-81be-430abe3f98e8',\n",
       " '175bcae2-6190-4052-a3b7-3c84abcbdd8e',\n",
       " '9218c50d-0363-4f74-8371-efc287e3656b',\n",
       " 'c956399e-1706-447f-825f-e5253ca7e2b8',\n",
       " '49aca15e-c1f1-48bb-b841-29aac3c27a14',\n",
       " '029e5e27-a756-4384-ad40-543881ef7bb7',\n",
       " 'd765501a-ed88-4ef3-8aa3-aff5606d3e7a',\n",
       " '28216cb4-84e9-472f-862e-24d676a1d0bc',\n",
       " '7e77b76e-7e72-4348-b521-cede53a64f11',\n",
       " '05b6c168-c578-4808-bac7-2b4528952d2a',\n",
       " 'e6e4b482-05a4-448e-aba6-e1d4cc5307c1',\n",
       " '10ec6540-6fe6-4b7c-9007-4c238c0a2c33',\n",
       " '61793fb6-48db-4fdf-9789-48178e438d43',\n",
       " '0bdbdc67-d77e-4a4e-bc91-f37615bac545',\n",
       " '6718ed32-14aa-4201-a0c7-c842fcdf0f30',\n",
       " '28a069ad-343f-45d7-b1bf-0ae0058fd0a6',\n",
       " '2a46390a-8629-49c2-9c59-cabf206adc8a',\n",
       " 'd8125165-6845-4f65-96be-d7fdd9e55260',\n",
       " '4c042189-c51e-4f3f-a816-3a6af4ce2257',\n",
       " '4d007b62-4e8a-48e8-af85-c0d81ede621e',\n",
       " 'ef80a4e3-a9ab-453a-8811-e7166eaaea12',\n",
       " '6ae62b16-bc23-4fb9-994a-cfcc8a202ff3',\n",
       " '1d2d29ec-c8cd-4767-9e0b-387d9d808af9',\n",
       " 'a2575c70-93a9-495a-af29-8556340100ea',\n",
       " '7bc7b263-aa72-4a16-9dbb-c822ac03ed6a',\n",
       " 'c9ee7583-5e2f-4fbc-865d-9d36f65c1876',\n",
       " 'f9cc3139-6b4b-4ae0-9823-6c0583579886',\n",
       " 'c91fa18c-89cd-465e-8946-ddd08e2edcc9',\n",
       " '0faf354d-4e1a-4dbe-9803-1b01ad48d2e8',\n",
       " 'c23e859d-0a0a-4972-abf9-23c6e54bb062',\n",
       " 'fe71b8ad-def1-4b7c-aee4-3d87d421532a',\n",
       " '6f5ac19a-0588-4a95-be3c-0581f975182d',\n",
       " 'd6255063-b55d-47bd-95d0-cc4550b193e7',\n",
       " '7b353e87-5ed1-4637-b930-55f94992f1d9',\n",
       " '15abfd79-ed4e-4232-b6ba-32fa5a393b49',\n",
       " 'a8a3569f-249e-49f2-8ca0-2b7cb6024f42',\n",
       " 'c41b04b9-1db3-438d-b843-fe19100f4c54',\n",
       " '223b92fc-8699-44d2-a872-8ba1048f1d3e',\n",
       " 'fbd7ffc1-c6b1-43bb-9413-963d9bf8c6a9',\n",
       " 'c51a251b-e267-4a20-9f76-794220c4627e',\n",
       " '82cefbee-e968-47d5-aefd-61444ab95c9b',\n",
       " 'dc1bf932-829e-4a80-866a-691e63ac9f1d',\n",
       " 'cb7cd00e-83fa-4891-bb9c-066e46007d7c',\n",
       " 'c152aa57-b061-47ea-b7de-c46d77c7ea6e',\n",
       " '2d735b12-e360-45e4-9bfb-eb906204d26e',\n",
       " '9fbfe2c4-204d-4be5-9bd2-9a9e485c265f',\n",
       " '13cc0369-c0dc-4357-a80e-1f919b742609',\n",
       " 'cfdff62e-4852-4d74-aa21-9a5661612f66',\n",
       " '3f646fa8-e493-4ac5-ada2-1b36693c3e32',\n",
       " '27fd109a-f524-4b1e-ae3a-4ef059a1d58e',\n",
       " 'c17c8a61-f2a9-48c9-aec6-1b5b7edd9195',\n",
       " '01904229-1b17-4cb4-b380-40e38ddfb227',\n",
       " '181d6bb7-a65a-4e57-b173-c4b4de2c547d',\n",
       " 'd1fc1e2f-f05d-4ba8-800a-f7955d817bd3',\n",
       " '049b8520-ddad-4c27-8f1b-db7cc20d8354',\n",
       " '6165367c-05ee-4d13-a5b3-224452335674',\n",
       " '2bcd9396-3b90-4c4d-8248-08f8869d1fdc',\n",
       " '794b0c97-3349-404c-8a3a-ec6f0e8f5b91']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(documents=split_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7aa0df",
   "metadata": {},
   "source": [
    "#### create retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba347ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vector_store.as_retriever(\n",
    "    search_kwargs={\"k\":5}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31319e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='01904229-1b17-4cb4-b380-40e38ddfb227', metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'syllabus.pdf', 'total_pages': 34, 'page': 31, 'page_label': '32'}, page_content='various use cases.\\nIntroduction to Retrieval-Augmented\\nGeneration (RAG)\\nTopics\\nOverview of Retrieval-Augmented\\nGeneration (RAG)\\nWhat is RAG?, Key Components of a\\nRAG System, Why RAG is Important for\\nAdvanced AI Systems\\nUnderstanding the End-to-End RAG\\nPipeline\\nOverview of the RAG Workflow, Data\\nRetrieval, Contextualization, and\\nGeneration Phases, Challenges and\\nOpportunities in RAG\\nIntegrating LangChain in RAG Introduction to LangChain Framework,\\nBuilding End-to-End RAG Pipelines with\\nLangChain'),\n",
       " Document(id='181d6bb7-a65a-4e57-b173-c4b4de2c547d', metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'syllabus.pdf', 'total_pages': 34, 'page': 31, 'page_label': '32'}, page_content='Building End-to-End RAG Pipelines with\\nLangChain\\nLeveraging Vector Databases in RAG Using Vector Databases for Efficient\\nRetrieval in RAG, Popular Vector\\nDatabases for RAG (e.g., Pinecone,\\nFAISS, Chroma DB)\\nRole of LLMs in RAG How LLMs (Large Language Models)\\nEnhance Generation in RAG, Fine-\\nTuning LLMs for Retrieval-Augmented\\nTasks\\nUltimate Data Science & GenAI Bootcamp       Page  32\\nModule 19'),\n",
       " Document(id='c17c8a61-f2a9-48c9-aec6-1b5b7edd9195', metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'syllabus.pdf', 'total_pages': 34, 'page': 31, 'page_label': '32'}, page_content='This module introduces the concept of Retrieval-Augmented Generation (RAG), which combines\\nretrieval-based search with generative models for enhanced language generation tasks. You’ll\\nlearn about the end-to-end RAG pipeline, including how to implement it with tools like LangChain,\\nvector databases, and LLMs. The module also covers hybrid search, reranking, and multimodal\\nretrieval techniques. By the end, you’ll understand how to implement advanced RAG systems for\\nvarious use cases.'),\n",
       " Document(id='fbd7ffc1-c6b1-43bb-9413-963d9bf8c6a9', metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'syllabus.pdf', 'total_pages': 34, 'page': 26, 'page_label': '27'}, page_content=\"This module covers Recurrent Neural Networks (RNNs) and Transformer models, focusing on their\\napplications in sequential data processing. You’ll learn how RNNs and LSTMs are used for time\\nseries analysis, speech recognition, and language modeling. The module also explores the\\nTransformer architecture, which powers models like BERT and GPT. By the end, you'll have a\\nstrong grasp of these advanced neural network architectures and their applications in NLP and\\nbeyond.\"),\n",
       " Document(id='dc1bf932-829e-4a80-866a-691e63ac9f1d', metadata={'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-01-30T20:27:03+00:00', 'title': 'Ultimate Data Science & GenAI Bootcamp', 'moddate': '2025-01-30T20:26:59+00:00', 'keywords': 'DAGdmhcqnYw,BAEmsmap8Lg,0', 'author': 'monal singh', 'containsaigeneratedcontent': 'Yes', 'source': 'syllabus.pdf', 'total_pages': 34, 'page': 27, 'page_label': '28'}, page_content='Deep Learning : Recurrent Neural\\nNetworks (RNN) and Transformer\\nModels\\nTopics\\nAttention Neural Networks Self-Attention in Neural Networks,\\nApplying Attention to RNNs, Transformer\\nvs RNN\\nBERT Model BERT (Bidirectional Encoder\\nRepresentations from Transformers),\\nPre-training and Fine-tuning BERT,\\nApplications of BERT in NLP\\nGPT-2 Model GPT-2 (Generative Pre-trained\\nTransformer 2), Autoregressive\\nLanguage Modeling, Fine-tuning GPT-2\\nfor Text Generation')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"Langchain\")\n",
    "\n",
    "## NOTE: if match result is 3 then 2 documents will be added to match k=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034317ed",
   "metadata": {},
   "source": [
    "### create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d92e90d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model=ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64b87102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\vijay\\work\\code\\AI\\AgenticAILearning\\venv\\Lib\\site-packages\\langsmith\\client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "prompt=hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb1d0dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c28ffa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3ebd3300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "018ff365",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain=(\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()} |\n",
    "    prompt | model | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "254fe5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain is a framework used to build end-to-end Retrieval-Augmented Generation (RAG) pipelines.  It integrates with vector databases and LLMs to enhance language generation tasks.  The framework is used in implementing advanced RAG systems for various use cases.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"tell me about langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58897a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain is a framework used to build end-to-end Retrieval-Augmented Generation (RAG) pipelines.  It integrates with vector databases and LLMs to enhance language generation tasks.  The provided text details its use in building RAG systems.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3336d1a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
